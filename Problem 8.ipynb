{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Problem Setup/Definition:\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from string import punctuation\n",
    "from string import digits\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction import text, stop_words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.svm import LinearSVC\n",
    "import math \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk import SnowballStemmer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_preprocessor(doc_string):\n",
    "    # do all data preprocessing here\n",
    "    \n",
    "    # Lower case\n",
    "    doc_string=doc_string.lower()\n",
    "    \n",
    "    # Remove Numbers\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    doc_string.translate(remove_digits)\n",
    "    \n",
    "    # Convert to tokenized form....\n",
    "    tokens = nltk.tokenize.word_tokenize(doc_string)\n",
    "    # Iterate through list of tokens (words) and remove all numbers\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Iterate through list of tokens (words) and stem (shorten) each word\n",
    "    port_stemmer = PorterStemmer()\n",
    "    tokens = [port_stemmer.stem(words) for words in tokens ]\n",
    "    \n",
    "    ###############################\n",
    "    #### Lemmatize with pos_tag ###\n",
    "    ###############################\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Convert between two different tagging schemes\n",
    "    def change_tags(penntag):\n",
    "        morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                      'VB':'v', 'RB':'r'}\n",
    "        try:\n",
    "            return morphy_tag[penntag[:2]]\n",
    "        except:\n",
    "            return 'n'\n",
    "        \n",
    "    tokens = [lemmatizer.lemmatize(word.lower(), pos=change_tags(tag)) for word, tag in pos_tag(tokens)]\n",
    "    \n",
    "    # Rejoin List of tokens and return that single document-string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "###########################\n",
    "#### RoC Curve Function ###\n",
    "###########################\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, lw=2, label= 'area under curve = %0.4f' % roc_auc)\n",
    "\n",
    "    ax.grid(color='0.7', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate',fontsize=15)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=15)\n",
    "\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    for label in ax.get_xticklabels()+ax.get_yticklabels():\n",
    "        label.set_fontsize(15)\n",
    "\n",
    "def fit_predict_and_plot_roc(pipe, train_data, train_label, test_data, test_label):\n",
    "    pipe.fit(train_data, train_label)\n",
    "\n",
    "    if hasattr(pipe, 'decision_function'):\n",
    "        prob_score = pipe.decision_function(test_data)\n",
    "        fpr, tpr, _ = roc_curve(test_label, prob_score)\n",
    "    else:\n",
    "        prob_score = pipe.predict_proba(test_data)\n",
    "        fpr, tpr, _ = roc_curve(test_label, prob_score[:,1])\n",
    "\n",
    "    plot_roc(fpr, tpr)\n",
    "    \n",
    "#####################################################\n",
    "#### Define Custom stop words for CountVectorizer ###\n",
    "#####################################################\n",
    "\n",
    "stop_words_skt = text.ENGLISH_STOP_WORDS\n",
    "stop_words_en = stopwords.words('english')\n",
    "combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))\n",
    "\n",
    "# Run stop_words through the same pre-processor as the document-matrix\n",
    "# This will apply stemmed/lemmatized stop_woirds to stemmed/lemmatized tokenized document lists\n",
    "def process_stop_words(stop_word_set):\n",
    "    doc_string = ' '.join(stop_word_set)\n",
    "    return my_custom_preprocessor(doc_string).split()\n",
    "\n",
    "################################\n",
    "#### Estimator Helper Class  ###\n",
    "################################\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "##################################\n",
    "#### Import Dataset Train/Test ###\n",
    "##################################\n",
    "\n",
    "# Only take a specific selection (4) of the 20 available categories\n",
    "categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "                'misc.forsale', 'soc.religion.christian']\n",
    "\n",
    "# Load a training & test data sets consisting of those 8 categories\n",
    "train_dataset = fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = None)\n",
    "test_dataset = fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = None)\n",
    "\n",
    "# Categories are mapped 0-4, (0-3) = Comp, (4-7) = Recreation\n",
    "# 0: comp.sys.ibm.pc.hardware\n",
    "# 1: comp.sys.mac.hardware\n",
    "# 2: misc.forsale\n",
    "# 3: soc.religion.christian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#### Trim Data Beforehand?? ###\n",
    "###############################\n",
    "## Using Discussion section code snippets\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "    \n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if word not in combined_stopwords and not word.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reduced TRAIN tf-idf matrix after NMF Dimensionality Reduction (top 50 words): (2352, 50)\n",
      "Shape of reduced TEST tf-idf matrix after NMF Dimensionality Reduction (top 50 words): (2352, 50)\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#### Naive Bayes Multiclass ###\n",
    "###############################\n",
    "# Define the CountVectorizer = document-term matrix\n",
    "train_count_vectorizer = CountVectorizer(min_df=3,analyzer=stem_rmv_punc, stop_words='english')\n",
    "test_count_vectorizer = CountVectorizer(min_df=3,analyzer=stem_rmv_punc, stop_words='english')\n",
    "\n",
    "# Fit + count the train_doc_term_matrix: setting the vocabulary (word-features) based on words found in the train_dataset\n",
    "train_doc_term_matrix = train_count_vectorizer.fit_transform(train_dataset.data)\n",
    "\n",
    "# Fit the test_count_doc_term_matric to train_dataset words; then count the occurence of those words in the test_dataset\n",
    "test_count_vectorizer.fit(train_dataset.data)\n",
    "test_count_doc_term_matrix = test_count_vectorizer.transform(test_dataset.data)\n",
    "\n",
    "# Start TD-DIF Transform process; created TDIF matrix with train_doc_term_matrix vocabulary; apply test_dataset transform\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_doc_term_matrix)\n",
    "test_tfidf = tfidf_transformer.fit_transform(test_count_doc_term_matrix)\n",
    "\n",
    "# Dimensionality Reduction: NMF\n",
    "nmf_settings = NMF(n_components=50, init='random', random_state=0)\n",
    "reduced_NMF_train_matrix = nmf_settings.fit_transform(train_tfidf)\n",
    "reduced_NMF_test_matrix = nmf_settings.transform(test_tfidf)\n",
    "\n",
    "nmf_settings_components = nmf_settings.components_\n",
    "print(\"Shape of reduced TRAIN tf-idf matrix after NMF Dimensionality Reduction (top 50 words): \" + str(reduced_NMF_train_matrix.shape))\n",
    "print(\"Shape of reduced TEST tf-idf matrix after NMF Dimensionality Reduction (top 50 words): \" + str(reduced_NMF_train_matrix.shape))\n",
    "print(\"\\n\\n\" + '-'*40 + \"\\n\\n\")\n",
    "\n",
    "# Gaussian Classifier: 'train_dataset.target' Now consists of 4 categories (0-3)\n",
    "train_gaus_model = GaussianNB().fit(reduced_NMF_train_matrix, train_dataset.target)\n",
    "predict_gaus_model = train_gaus_model.predict(reduced_NMF_test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Naive Bayes: Gaus Stats ############### \n",
      "\n",
      "Accuracy: 0.7559105431309904\n",
      "Precision: 0.7572224492772439\n",
      "Recall: 0.7542536907935328\n",
      "F1-score: [0.41473146 0.65114622 0.41473146 ... 0.30426171 0.41473146 0.65114622]\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[276  42  66   8]\n",
      " [ 86 222  73   4]\n",
      " [ 56  34 295   5]\n",
      " [  2   2   4 390]]\n",
      "\n",
      "Multiclass metrics: \n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.ibm.pc.hardware       0.66      0.70      0.68       392\n",
      "   comp.sys.mac.hardware       0.74      0.58      0.65       385\n",
      "            misc.forsale       0.67      0.76      0.71       390\n",
      "  soc.religion.christian       0.96      0.98      0.97       398\n",
      "\n",
      "                accuracy                           0.76      1565\n",
      "               macro avg       0.76      0.75      0.75      1565\n",
      "            weighted avg       0.76      0.76      0.75      1565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot Gaus Model Statistics:\n",
    "gaus_accuracy = metrics.accuracy_score(test_dataset.target, predict_gaus_model)\n",
    "gaus_precision = metrics.precision_score(test_dataset.target, predict_gaus_model, average='macro')\n",
    "gaus_recall = metrics.recall_score(test_dataset.target, predict_gaus_model, average='macro')\n",
    "gaus_f1 = 2 * (gaus_precision * gaus_recall) / (predict_gaus_model + gaus_recall)\n",
    "print(\"############## Naive Bayes: Gaus Stats ############### \\n\")\n",
    "print(\"Accuracy: \" + str(gaus_accuracy))\n",
    "print(\"Precision: \" + str(gaus_precision))\n",
    "print(\"Recall: \" + str(gaus_recall))\n",
    "print(\"F1-score: \"+ str(gaus_f1))\n",
    "print(\"\\nConfusion Matrix: \\n\\n\" + str(metrics.confusion_matrix(test_dataset.target, predict_gaus_model)))\n",
    "print(\"\\nMulticlass metrics: \")\n",
    "print(metrics.classification_report(test_dataset.target, predict_gaus_model, target_names=['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'misc.forsale', 'soc.religion.christian']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Linear SVC Multiclass 1v1 ############### \n",
      "\n",
      "Accuracy: 0.8440894568690096\n",
      "Precision: 0.845718313150106\n",
      "Recall: 0.8431846061332781\n",
      "F1-score: [0.50161826 0.77376586 0.50161826 ... 0.37109675 0.50161826 1.69143663]\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[310  57  25   0]\n",
      " [ 74 284  25   2]\n",
      " [ 33  15 342   0]\n",
      " [  7   3   3 385]]\n",
      "\n",
      "Multiclass metrics: \n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.ibm.pc.hardware       0.73      0.79      0.76       392\n",
      "   comp.sys.mac.hardware       0.79      0.74      0.76       385\n",
      "            misc.forsale       0.87      0.88      0.87       390\n",
      "  soc.religion.christian       0.99      0.97      0.98       398\n",
      "\n",
      "                accuracy                           0.84      1565\n",
      "               macro avg       0.85      0.84      0.84      1565\n",
      "            weighted avg       0.85      0.84      0.84      1565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#### Linear SVC Multiclass 1v1 ###\n",
    "##################################\n",
    "# Use OneVsOneClassifier() to get the correct decision_function() return shape\n",
    "linear_classifier_1v1 = OneVsOneClassifier(SVC(C=100.0, max_iter=5000, kernel='linear',random_state=0))\n",
    "fitted_linear_classifier_1v1 = linear_classifier_1v1.fit(reduced_NMF_train_matrix, train_dataset.target)\n",
    "predicted_linear_classifier_1v1 = fitted_linear_classifier_1v1.predict(reduced_NMF_test_matrix)\n",
    "\n",
    "# Plot Linear SVC 1v1 Statistics:\n",
    "linear_1v1__accuracy = metrics.accuracy_score(test_dataset.target, predicted_linear_classifier_1v1)\n",
    "linear_1v1__precision = metrics.precision_score(test_dataset.target, predicted_linear_classifier_1v1, average='macro')\n",
    "linear_1v1__recall = metrics.recall_score(test_dataset.target, predicted_linear_classifier_1v1, average='macro')\n",
    "linear_1v1__f1 = 2 * (linear_1v1__precision * linear_1v1__recall) / (predicted_linear_classifier_1v1 + linear_1v1__recall)\n",
    "print(\"############## Linear SVC Multiclass 1v1 ############### \\n\")\n",
    "print(\"Accuracy: \" + str(linear_1v1__accuracy))\n",
    "print(\"Precision: \" + str(linear_1v1__precision))\n",
    "print(\"Recall: \" + str(linear_1v1__recall))\n",
    "print(\"F1-score: \"+ str(linear_1v1__f1))\n",
    "print(\"\\nConfusion Matrix: \\n\\n\" + str(metrics.confusion_matrix(test_dataset.target, predicted_linear_classifier_1v1)))\n",
    "print(\"\\nMulticlass metrics: \")\n",
    "print(metrics.classification_report(test_dataset.target, predicted_linear_classifier_1v1, target_names=['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'misc.forsale', 'soc.religion.christian']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Linear SVC Multiclass 1vrest ############### \n",
      "\n",
      "Accuracy: 0.853035143769968\n",
      "Precision: 0.8522017159752234\n",
      "Recall: 0.8521182260548735\n",
      "F1-score: [0.50921915 0.78415795 0.50921915 ... 0.37702717 0.50921915 1.70440343]\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[309  56  24   3]\n",
      " [ 67 288  26   4]\n",
      " [ 27  15 347   1]\n",
      " [  4   2   1 391]]\n",
      "\n",
      "Multiclass metrics: \n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.ibm.pc.hardware       0.76      0.79      0.77       392\n",
      "   comp.sys.mac.hardware       0.80      0.75      0.77       385\n",
      "            misc.forsale       0.87      0.89      0.88       390\n",
      "  soc.religion.christian       0.98      0.98      0.98       398\n",
      "\n",
      "                accuracy                           0.85      1565\n",
      "               macro avg       0.85      0.85      0.85      1565\n",
      "            weighted avg       0.85      0.85      0.85      1565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#### Linear SVC Multiclass 1vrest ###\n",
    "#####################################\n",
    "# Use OneVsRestClassifier() to get the correct decision_function() return shape\n",
    "linear_classifier_1vrest = OneVsRestClassifier(SVC(C=100.0, max_iter=5000, kernel='linear',random_state=0))\n",
    "fitted_linear_classifier_1vrest = linear_classifier_1vrest.fit(reduced_NMF_train_matrix, train_dataset.target)\n",
    "predicted_linear_classifier_1vrest = fitted_linear_classifier_1vrest.predict(reduced_NMF_test_matrix)\n",
    "\n",
    "# Plot Linear SVC 1vrest Statistics:\n",
    "linear_1vrest_accuracy = metrics.accuracy_score(test_dataset.target, predicted_linear_classifier_1vrest)\n",
    "linear_1vrest_precision = metrics.precision_score(test_dataset.target, predicted_linear_classifier_1vrest, average='macro')\n",
    "linear_1vrest_recall = metrics.recall_score(test_dataset.target, predicted_linear_classifier_1vrest, average='macro')\n",
    "linear_1vrest_f1 = 2 * (linear_1vrest_precision * linear_1vrest_recall) / (predicted_linear_classifier_1vrest + linear_1vrest_recall)\n",
    "print(\"############## Linear SVC Multiclass 1vrest ############### \\n\")\n",
    "print(\"Accuracy: \" + str(linear_1vrest_accuracy))\n",
    "print(\"Precision: \" + str(linear_1vrest_precision))\n",
    "print(\"Recall: \" + str(linear_1vrest_recall))\n",
    "print(\"F1-score: \"+ str(linear_1vrest_f1))\n",
    "print(\"\\nConfusion Matrix: \\n\\n\" + str(metrics.confusion_matrix(test_dataset.target, predicted_linear_classifier_1vrest)))\n",
    "print(\"\\nMulticlass metrics: \")\n",
    "print(metrics.classification_report(test_dataset.target, predicted_linear_classifier_1vrest, target_names=['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'misc.forsale', 'soc.religion.christian']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
